# 化繁而简
> 个人相信大部分技术的原理是复杂的,但实践一定是简单的。如果此项技术不能做到简单运用,那么这项技术流传过程中一定会不断的精进,最终进化一个大多数人都容易接受的方式

# JMM
## 可见性

针对可见性个人认为有一段话写得不错,于是摘抄下来,引用[文章地址](https://blog.csdn.net/tjcwt2011/article/details/123652951)

程序是工作在OS，编译器，物理硬件共同营造的虚拟环境中的，（在本文中，我们把这个环境称为”程序运行环境“），程序运行环境有一定的规则，不同的OS/编译器/CPU等有千万种方法来实现这个规则，但这个规则本身是不变的，我们要看到这个规则，而不是看到实现，规则和实现是交织在一起的，架构眼光就是要从所有的实现中看到不变的部分（承诺的规则）和可变的部分（实现的规则）。
  
  先看如下程序序列：
```shell script
  a=1;
  b=2;
  c=a+b;
  printf("a=%d, b=%d, c=%d\n", a, b, c);
```  
   
  上面这个程序序列，作用于程序运行环境的时候，环境规则能承诺的是，计算c的时候，a肯定等于1，b肯定等于2。最后打印的时候，c肯定等于3。
  
  但它没有承诺的是：
  
  1. a，b，c是内存上的地址（也可以是寄存器一类的东西）
  
  2. a首先变成1，然后b才变成2
  
  3. 如果其他设备或者CPU修改这些内存地址，反应是什么
  
  4. 等等
  
  所以，编译器和CPU在满足前面的规则的时候，总是玩各种小九九，在满足前面”承诺“的规则的前提下，（非有意地）破坏没有承诺的规则。
  
  这种破坏不但出现在Cache上，还常常出现在如下位置上：
  
  1. 编译器：编译器通过重排指令的顺序，可以充分利用寄存器和流水线，所以，编译器有可能把b=2排到a=1的前面
  
  2. 指令调度器：指令调度器可以对指令执行的步骤进行重排，甚至可以随意修改寄存器的索引名，这会引起指令生效时间的改变
  
  3. 指令发射器：多Issue的CPU，可以同步发出多条没有依赖的指令，这些指令的先后顺序受CPU执行影响，不一定和软件输入的一致
  
  4. Cache系统：即使保证了指令的发射依赖，Cache到达内存的时间，也受Cache的多级调度算法影响
  
  5. 等等
  
  但是，程序只有一个，程序不能为你考虑你编译器的问题，不能为你考虑指令发射的问题。程序如果每下去一个操作都要想想这个操作会在cache上形成怎样的执行序列，编译器又会怎样进行编排，程序不用写了。所以，在SMP系统中，Linux增加了smp_mb()系列的操作，这些操作，在不同平台上有不同的实现，但无论是哪个实现，必须遵守新的规则：
  
  当smp_mb()结束后，对本CPU来说，运行环境一定可以保证smb_mb()之前的内存操作已经完成，并反应到对应的内存子系统中。
  
  同时，内存子系统中所有的未竟操作，在smp_mb()后，必须对本CPU生效。
  
  基于这两条规则，我们很容易理解例子中的那个案例，为什么在第一个线程已经使用smp_mb()的情况下，第二个线程还需要使用一次smp_mb()，因为第一个线程只保证了这种依赖对本CPU和内存子系统生效，并不保证对第二个CPU（那个CPU有自己的Cache等运行环境系统）也生效，如果那个CPU不做smp_mb()操作，外界的这种变化就不会反应到这个CPU上。
  
  mb()系列调用和这个类似，不过面对的是系统的CPU和IO，而不是CPU与CPU而已。
Jvm为了满足可见性,提供了多种实现,例如关键字(volatile、Synchronized,LockSupport)。但是实现可见性的原理无法两种
第一种: 线程切换(LockSupport)

### 线程切换的过程
- 保存当前线程的上下文：当发生线程切换时，首先需要保存当前线程的执行上下文信息，包括程序计数器（PC）的值，用于指示线程下一条要执行的指令地址；CPU 寄存器的值，如通用寄存器、指令指针寄存器等，这些寄存器中存储着线程执行过程中的中间结果和状态信息；以及其他与线程执行相关的状态信息，如栈指针等。这些上下文信息会被保存在该线程的内核栈或特定的线程控制块（TCB）中。
- 选择下一个要执行的线程：操作系统根据调度算法从就绪队列中选择一个线程作为下一个要执行的线程。调度算法会综合考虑线程的优先级、等待时间、执行时间等因素来确定线程的执行顺序，以实现系统资源的合理分配和高效利用。
- 恢复下一个线程的上下文：一旦确定了下一个要执行的线程，操作系统会从该线程的内核栈或 TCB 中恢复其之前保存的上下文信息，将程序计数器、CPU 寄存器等设置为相应的值，使得 CPU 能够从上次暂停的位置继续执行该线程，就好像线程从未被中断过一样。
### 线程切换的开销
- 时间开销：线程切换需要一定的时间来完成上述的保存和恢复上下文等操作，这会导致 CPU 在一段时间内无法执行有效的任务，从而降低了 CPU 的利用率。尤其是在频繁进行线程切换的情况下，时间开销会累积，对系统性能产生较大的影响。
- 空间开销：为了保存线程的上下文信息，需要占用一定的内核栈空间或额外的内存空间来存储 TCB 等数据结构。如果系统中存在大量的线程，这些空间开销也会不容忽视，可能会导致系统内存资源的紧张。
- 缓存失效开销：当线程切换时，新线程的数据和指令可能不在 CPU 缓存中，需要重新从内存中加载，这会导致缓存失效，增加了内存访问的延迟，进一步降低了系统的性能。尤其是对于频繁访问的数据和指令，缓存失效的影响更为明显。

总结下来:线程切换的时候,Cpu会重新加载上下文信息,重新将内存数据加载到本地缓存中

第二种: 使用内存屏障(volatile)
内存屏障对于不理解计算机组成原理的人,相当抽象,但个人理解下来就是一句话。
通过内存屏障可以要求计算机执行的操作顺序,如同你所见的顺序，防止在多线程环境下由于指令重排序等优化措施导致的数据不一致问题，从而保证了多线程程序能够正确地共享和访问内存中的数据。


### 缓存一致性问题的产生
在多处理器系统中，每个处理器都有自己的缓存，用于存储从内存中读取的数据和指令。当多个处理器同时访问和修改共享内存中的数据时，就可能会出现缓存一致性问题。具体来说，由于缓存的存在，一个处理器对共享变量的修改可能不会立即被其他处理器看到，导致不同处理器的缓存中保存的同一共享变量的值不一致。这种不一致性可能会引发程序的错误行为，例如数据竞争、计算结果错误等。

内存屏障的作用原理
### 阻止指令重排序：
内存屏障可以防止指令重排序跨越内存屏障。在没有内存屏障的情况下，处理器和编译器为了提高性能，可能会对指令进行重排序，只要这种重排序不改变单线程程序的语义。然而，在多线程程序中，这种重排序可能会导致意想不到的结果。内存屏障确保在屏障两侧的指令按照程序中指定的顺序执行，从而避免了因指令重排序而引起的缓存一致性问题。
强制内存操作的顺序性：内存屏障强制规定了在屏障之前的内存操作一定先于屏障之后的内存操作完成。对于写内存屏障，它确保在屏障之前的所有写操作都先于屏障之后的写操作被提交到内存中，并且对其他处理器可见；对于读内存屏障，它确保在屏障之后的所有读操作都在屏障之前的读操作之后执行，并且能够读取到屏障之前的所有写操作的结果。通过这种方式，内存屏障保证了不同处理器对共享变量的读写操作按照正确的顺序执行，从而维护了缓存的一致性。
### 不同类型内存屏障的具体作用
#### 写内存屏障（Store Memory Barrier）：
当一个处理器执行到写内存屏障时，它会等待在屏障之前的所有写操作都完成并更新到内存中，然后再执行屏障之后的写操作。这就确保了一个处理器对共享变量的写操作能够按照程序中指定的顺序被其他处理器看到，防止了写操作的乱序执行导致的缓存不一致。例如，处理器 A 先对共享变量 x 进行写操作，然后执行写内存屏障，接着对共享变量 y 进行写操作。此时，其他处理器在访问 x 和 y 时，一定能够先看到处理器 A 对 x 的写操作结果，然后才是对 y 的写操作结果，保证了缓存中数据的一致性。
#### 读内存屏障（Load Memory Barrier）：
读内存屏障确保在屏障之后的所有读操作都在屏障之前的读操作之后执行，并且能够读取到屏障之前的所有写操作的结果。假设处理器 B 先执行读内存屏障，然后读取共享变量 m 的值，接着读取共享变量 n 的值。在读内存屏障的作用下，处理器 B 能够确保读取到的 n 的值是在读取 m 的值之后最新的结果，并且包含了在读取 m 之前所有其他处理器对 n 的写操作的结果，避免了因读操作的乱序执行而导致读取到陈旧数据，从而维护了缓存中数据的一致性。
#### 全内存屏障（Full Memory Barrier）：
全内存屏障兼具写内存屏障和读内存屏障的功能，它确保在屏障之前的所有内存操作（包括读和写）都在屏障之后的所有内存操作之前完成。全内存屏障提供了最强的内存顺序保证，能够有效地解决复杂的缓存一致性问题，但同时也可能会带来较大的性能开销。例如，在一些需要严格保证数据一致性的场景中，如金融交易系统、航空航天控制系统等，可能会使用全内存屏障来确保不同处理器之间的内存操作的严格顺序，避免因缓存不一致而导致的严重后果。 
 


